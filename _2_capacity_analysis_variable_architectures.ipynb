{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from figures import er_replay_capacity as fig_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replay capacity analysis\n",
    "\n",
    "How many different sequences can a network reliably replay? Mathematically, this is equivalent to asking how many sequences can be specified purely through an unordered *set* of involved ensembles (marked by lingering hyperexcitability), and through the first ensemble in the sequence. This so-called replay capacity will of course depend on the network architecture. In this analysis, we restrict our analysis to networks with binary, directed connections.\n",
    "\n",
    "Importantly, there should be a nontrivial connectivity matrix that maximizes the replay capacity of a network. If the network has no connections, no sequences can be specified by a set of hyperexcitable ensembles: after the first ensemble activates, all other hyperexcitable ensembles will activate with equal probability, since none of them receives input from the first ensemble. On the other hand, no sequences can be specified in a fully connected network either, since after the first ensemble activates, again all other hyperexcitable ensembles will activate with equal probability, since they always receive increased but equal input from the first ensemble.\n",
    "\n",
    "Here we quantify the replay capacity of networks with a variety of different connectivities. To perform this calculation we precisely define the replay capacity of a network to be the number of replayable sequences it contains, where we call a sequence of ensembles replayable if the following is true:\n",
    "\n",
    "Given the first ensemble, only one possible path through the *set* of the later ensembles can be traced by following the connections present in the network.\n",
    "\n",
    "This simply quantifies the notion that if one knows the *set* of ensembles in the sequence as well as the starting ensemble, then there should be no ambiguity in determining the order. For example:\n",
    "\n",
    "<img src=\"files/images/reliable_replayability_example.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the *replay capacity* $R_L(C)$ of a network given its connectivity structure $C$ (a binarized version of its weight matrix) as the number of reliably replayable sequences of length $L$ that exist in the network. Specifically:\n",
    "\n",
    "$$R_L(C) = \\sum_\\limits{path \\in \\{ \\textrm{paths of length } L \\} } \\mathbb{1}[path \\textrm{ is replayable }].$$\n",
    "\n",
    "\n",
    "Notably $R_L(C) = 0$ when $C$ is completely unconnected (because there are no paths to sum over) and when $C$ is fully connected (because while all possible paths exist, none is replayable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For simplicity, we'll only consider paths that start and end at different nodes ($i \\neq j$), which will be a lower limit on the total number of replayable paths. For a given random network, one can calculate $E[R_L(C)]$ in the following way:\n",
    "\n",
    "$$E[R_L(C)] = E\\left[\\sum_{i, j} n_R^L(i, j) \\right] = \n",
    "\\sum_{i, j} E\\left[n_R^L(i, j)\\right]$$\n",
    "\n",
    "where $n_R^L(i, j)$ is the number of reliably replayable paths that start at $i$ and end at $j$. However, if the nodes are indexed randomly, then $E[n_R^L(i, j)] = E[n_R^L(k, l)]$, and so:\n",
    "\n",
    "$$ \\sum_{i, j} E\\left[n_R^L(i, j)\\right] = N(N-1) E\\left[n_R^L(i, j)\\right]$$\n",
    "Thus, one only needs to calculate the expected number of paths between two randomly chosen nodes.\n",
    "\n",
    "In certain cases the following further simplification is also useful:\n",
    "\n",
    "$$E\\left[n_R^L(i, j)\\right] = E\\left[ \\sum_{\\textrm{possible paths from i to j}} \\mathbb{1} \\left[\\textrm{path exists and is replayable} \\right] \\right]$$\n",
    "\n",
    "$$ = \\sum_{\\textrm{possible paths from i to j}} E\\left[ \\mathbb{1} \\left[\\textrm{path exists and is replayable} \\right] \\right]$$\n",
    "\n",
    "$$ = \\sum_{\\textrm{possible paths from i to j}} p\\left(\\textrm{path exists and is replayable} \\right).$$\n",
    "\n",
    "Again, if nodes are indexed randomly in the graph generation process, then we have:\n",
    "\n",
    "$$ \\sum_{\\textrm{possible paths from i to j}} p\\left(\\textrm{path exists and is replayable} \\right)$$\n",
    "\n",
    "$$ = (N-2)(N-3)...(N-L+1) p\\left(\\textrm{path exists and is replayable} \\right)$$\n",
    "\n",
    "$$ = \\cfrac{(N-2)!}{(N-L)!} p\\left(\\textrm{path exists and is replayable} \\right)$$\n",
    "\n",
    "Therefore the total expected number of replayable paths in a random network is\n",
    "\n",
    "$$E\\left[R_L(C)\\right] = \\cfrac{N!}{(N-L)!} p\\left(\\textrm{path exists and is replayable}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the calculation of $E[R_L(C)]$ for a random graph is reduced to the calculation of the probability that there is a replayable path through a single randomly chosen sequence of nodes. In general, this can be decomposed as:\n",
    "\n",
    "$$p(\\textrm{path exists and is replayable})$$\n",
    "\n",
    "$$ = p(\\textrm{path exists}) p(\\textrm{path is replayable } | \\textrm{ path exists}).$$\n",
    "\n",
    "And this is simply the probability that, excepting the last node of the sequence, each node connects to the next node in the sequence but to no other nodes in the sequence. As our reference point we will use the maximum number of possible length-$L$ sequences: $N^L$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erdos-Renyi random graph\n",
    "\n",
    "In an Erdos-Renyi network, each ordered pair of nodes is connected with a probability $q$. Thus,\n",
    "\n",
    "$$p(\\textrm{path exists}) = q^{(L-1)}.$$\n",
    "\n",
    "The probability that there are no other edges from any node (except the last) to any other node besides the next one in the sequence is:\n",
    "\n",
    "$$p(\\textrm{path is replayable }|\\textrm{ path exists}) = (1 - q)^{(L-1)(L-2)}.$$\n",
    "\n",
    "Thus for the ER network we have:\n",
    "\n",
    "$$E\\left[R_L(C_{ER})\\right] = \\cfrac{N!}{(N-L)!}q^{(L-1)}(1 - q)^{(L-1)(L-2)}.$$\n",
    "\n",
    "For a fixed $L$, $E[R_L(C_{ER})]$ as a function of $N$ is given by\n",
    "\n",
    "$$A(L)N(N-1)...(N-L+1) = A(L)(N^L + B(L)N^{L-1} + ...) \\sim O(N^L).$$\n",
    "\n",
    "And so the replay capacity for the ER network is approximately a constant fraction of $N^L$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also show that for $N$ sufficiently large, the expected replay capacity increases with $L$. To do this, we want to show that\n",
    "\n",
    "$$\\cfrac{E[R_{L_2}(C_{ER})]}{E[R_{L_1}(C_{ER})]} > 1$$\n",
    "\n",
    "when $L_2 > L_1$. This ratio equals\n",
    "\n",
    "$$\\cfrac{\\cfrac{N!}{(N-L_2)!}q^{(L_2-1)}(1 - q)^{(L_2-1)(L_2-2)}}{\\cfrac{N!}{(N-L_1)!}q^{(L_1-1)}(1 - q)^{(L_1-1)(L_1-2)}}$$\n",
    "\n",
    "$$ = \\cfrac{(N-L_1)!}{(N-L_2)!}q^{L_2-L_1}(1-q)^{(L_2-L_1)(L_1 + L_2 - 3)}$$\n",
    "\n",
    "$$ = (N-L_1)(N-L_1-1)\\dots(N-L_2+1)q^{L_2-L_1}(1-q)^{(L_2-L_1)(L_1 + L_2 - 3)}$$\n",
    "\n",
    "$$ > (N-L_2+1)^{L_2 - L_2}q^{L_2-L_1}(1-q)^{(L_2-L_1)(L_1 + L_2 - 3)}$$\n",
    "\n",
    "$$ = (q(N - L_2 + 1))^{L_2 - L_1}(1-q)^{(L_2-L_1)(L_1 + L_2 - 3)} .$$\n",
    "\n",
    "Since the both terms of this are positive, and the exponent $(L_2 - L_1)$ of the first term is greater than 1, the full quantity will increase monotonically with $N$. Therefore, for $N$ sufficiently large:\n",
    "\n",
    "$$(q(N - L_2 + 1))^{L_2 - L_1}(1-q)^{(L_2-L_1)(L_1 + L_2 - 3)} > 1.$$\n",
    "\n",
    "Thus for any $q \\notin \\{0, 1\\}$, the expected replay capacity increases with $L$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, since the replay capacity is $0$ when $q = 0$ or $q = 1$, there will be an optimal $q^*$ for each $L$, and this will simply be given by the argmax of \n",
    "\n",
    "$$f(q) = q^{L-1}(1 - q)^{(L-1)(L-2)}.$$\n",
    "\n",
    "We find this by setting to $df/dq = 0$. Specifically:\n",
    "\n",
    "$$0 = (L-1){q^*}^{L-2}(1 - q^*)^{(L-1)(L-2)} - {q^*}^{L-1}(L-1)(L-2)(1 - q^*)^{(L-1)(L-2) - 1}$$\n",
    "\n",
    "$$ = (1 - q^*) - q^*(L-2) = 1 - (L - 1)q^*$$\n",
    "\n",
    "So\n",
    "\n",
    "$$q^* = \\cfrac{1}{L-1}.$$\n",
    "\n",
    "Thus, the optimal $q$ decreases with $L$, or in other words, increasing the length of the sequences you want to replay requires increasing the sparseness of the network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
