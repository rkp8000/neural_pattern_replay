{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from figures import single_time_point_decoding_vs_weight_matrix as fig_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How is stimulus decodability affected when the network's connectivity mirrors the external stimulus transitions? To ask this,  first imagine that activation-dependent hyperexcitability has been switched off by some global mechanism such as neuromodulation. Indeed, early working memory studies showed that stimulus-repetition-dependent hyperexcitability could be gated by task-relevant variables ([Miller et al., 1994][Miller1994]). Further since hyperexcitability shifts a decoder readout towards previous stimuli, it would make sense to turn this off in order to read out current stimuli.\n",
    "\n",
    "Next imagine a Markovian stimulus that transitions among a discrete set of states over time according to the probability $P(S_t = s_i|S_{t-1} = s_j)$, with one state corresponding to each ensemble. The network's activation $A_t$ is determined by both the previous activation and the incoming stimulus according to $P(A_t = i|A_{t-1}, S_t)$. That is, both the network and the stimulus transition through parallel sets of states, with the stimulus partially influencing the network's transitions, as in the figure below:\n",
    "\n",
    "<img src=\"files/images/network_and_stimulus_transitions_unmatched.png\" width=\"300px\"/>\n",
    "\n",
    "Now imagine a decoder that at each time step simply chooses the stimulus corresponding to the active ensemble (e.g., if ensemble 84 was active, the readout of the decoder is *stimulus 84*). How is the decoding accuracy (the probability that the decoder is correct, averaged over time) affected when the network transitions mirror the stimulus transitions, as in the diagram below?\n",
    "\n",
    "<img src=\"files/images/network_and_stimulus_transitions_matched.png\" width=\"300px\"/>\n",
    "\n",
    "At a given time step, there are two cases to consider. On the one hand, if the last active ensemble *matched* the last stimulus, decoding should improve. This is because downstream ensembles receiving increased input from the last active ensemble will tend to line up with likely stimuli, since the connectivity mirrors the stimulus transitions. On the other hand, if the last active ensemble *did not match* the last stimulus, decoding should worsen. This is because the downstream ensembles receiving increased input will have little to do with the current stimulus, thereby shifting activation probability mass on average away from the ensemble corresponding to the correct stimulus.\n",
    "\n",
    "[Miller1994]: http://science.sciencemag.org/content/263/5146/520"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we consider 5 different connectivity structures, relative to the stimulus transition probabilities: (1) connectivity matched to the stimulus transitions, (2) zero connectivity, (3) connectivity half-matched to the stimulus transitions and half zero, (4) random connectivity, and (5) full connectivity. To choose a stimulus transition matrix that is easily matchable by a connectivity matrix, we build the connectivity matrix $W_{matched}$ first, and then calculate the corresponding transition probabilities using the softmax function to $P(S_t|S_{t-1})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'SEED': 0,  # FOR RANDOM NUMBER GENERATOR\n",
    "    \n",
    "    'N_NODES': 100,  # NUMBER OF NODES\n",
    "    'P_CONNECT': .2,  # ERDOS-RENYI CONNECTION PROBABILITY\n",
    "    \n",
    "    'G_W': 5,  # GAIN ON PROJECTION WEIGHTS (ALL W_IJ ARE 1 OR 0)\n",
    "    'G_DS': np.linspace(0, 10, 20, endpoint=True),  # GAINS ON STIMULUS DRIVE\n",
    "    'G_D_EXAMPLE': 4,  # STIMULUS DRIVE GAIN FOR EXAMPLE DECODING\n",
    "    'N_TIME_POINTS': 2000,  # NUMBER OF TIME POINTS TO DECODE\n",
    "    \n",
    "    'FIG_SIZE': (15, 8),\n",
    "    'FONT_SIZE': 16,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig_1(**CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 1: Stimulus decodability depends on the relationship between the network connectivity and the stimulus transition probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, we see that whereas decoding accuracy is significantly impaired when the connectivity is random or only half matches the stimulus transitions, the accuracy is equal for zero connectivity, full connectivity, and connectivity precisely matched to the stimulus transitions. Thus, the effects of the two possible cases described above (which improve and worsen stimulus decodability, respectively) seem to exactly cancel out in our model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
